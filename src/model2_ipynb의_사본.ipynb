{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model2.ipynb의 사본",
      "provenance": [],
      "mount_file_id": "1f4UWoE-oqf-Ul516lILlQthZ6nGCym9Q",
      "authorship_tag": "ABX9TyOdimNRT2+fz/SsIobcpSo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aloml2543/KB_OCR/blob/main/src/model2_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wBMDl-gHVaY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p66CA_iJ20lU",
        "outputId": "ed800f8a-3eca-4dd9-ce03-f469db59496f"
      },
      "source": [
        "!pip install hangul_utils\n",
        "import numpy as np\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "from hangul_utils import split_syllables, join_jamos\n",
        "\n",
        "\n",
        "class hangle_hanza():\n",
        "  def __init__(self):\n",
        "    !unzip -n \"/content/drive/MyDrive/KB_OCR/model2/Font2.zip\"  -d '/content/Font/'\n",
        "    self.charecter = '''0123456789abcdefghijklmnopqrstuvwxyz가각간갇갈감갑값갓강갖같갚갛개객걀걔거걱건걷걸검겁것겉게겨격겪견결겹경곁계고곡곤곧골곰곱곳공과관광괜괴굉교구국군굳굴굵굶굽궁권귀귓규균귤그극근글긁금급긋긍기긴길김깅깊까깍깎깐깔깜깝깡깥깨꺼꺾껌껍껏껑께껴꼬꼭꼴꼼꼽꽂꽃꽉꽤꾸꾼꿀꿈뀌끄끈끊끌끓끔끗끝끼낌나낙낚난날낡남납낫낭낮낯낱낳내냄냇냉냐냥너넉넌널넓넘넣네넥넷녀녁년념녕노녹논놀놈농높놓놔뇌뇨누눈눕뉘뉴늄느늑는늘늙능늦늬니닐님다닥닦단닫달닭닮담답닷당닿대댁댐댓더덕던덜덟덤덥덧덩덮데델도독돈돌돕돗동돼되된두둑둘둠둡둥뒤뒷드득든듣들듬듭듯등디딩딪따딱딴딸땀땅때땜떠떡떤떨떻떼또똑뚜뚫뚱뛰뜨뜩뜯뜰뜻띄라락란람랍랑랗래랜램랫략량러럭런럴럼럽럿렁렇레렉렌려력련렬렵령례로록론롬롭롯료루룩룹룻뤄류륙률륭르른름릇릎리릭린림립릿링마막만많말맑맘맙맛망맞맡맣매맥맨맵맺머먹먼멀멈멋멍멎메멘멩며면멸명몇모목몬몰몸몹못몽묘무묵묶문묻물뭄뭇뭐뭘뭣므미민믿밀밉밌및밑바박밖반받발밝밟밤밥방밭배백뱀뱃뱉버번벌범법벗베벤벨벼벽변별볍병볕보복볶본볼봄봇봉뵈뵙부북분불붉붐붓붕붙뷰브븐블비빌빔빗빚빛빠빡빨빵빼뺏뺨뻐뻔뻗뼈뼉뽑뿌뿐쁘쁨사삭산살삶삼삿상새색샌생샤서석섞선설섬섭섯성세섹센셈셋셔션소속손솔솜솟송솥쇄쇠쇼수숙순숟술숨숫숭숲쉬쉰쉽슈스슨슬슴습슷승시식신싣실싫심십싯싱싶싸싹싼쌀쌍쌓써썩썰썹쎄쏘쏟쑤쓰쓴쓸씀씌씨씩씬씹씻아악안앉않알앓암압앗앙앞애액앨야약얀얄얇양얕얗얘어억언얹얻얼엄업없엇엉엊엌엎에엔엘여역연열엷염엽엿영옆예옛오옥온올옮옳옷옹와완왕왜왠외왼요욕용우욱운울움웃웅워원월웨웬위윗유육율으윽은을음응의이익인일읽잃임입잇있잊잎자작잔잖잘잠잡잣장잦재쟁쟤저적전절젊점접젓정젖제젠젯져조족존졸좀좁종좋좌죄주죽준줄줌줍중쥐즈즉즌즐즘증지직진질짐집짓징짙짚짜짝짧째쨌쩌쩍쩐쩔쩜쪽쫓쭈쭉찌찍찢차착찬찮찰참찻창찾채책챔챙처척천철첩첫청체쳐초촉촌촛총촬최추축춘출춤춥춧충취츠측츰층치칙친칠침칫칭카칸칼캄캐캠커컨컬컴컵컷케켓켜코콘콜콤콩쾌쿄쿠퀴크큰클큼키킬타탁탄탈탑탓탕태택탤터턱턴털텅테텍텔템토톤톨톱통퇴투툴툼퉁튀튜트특튼튿틀틈티틱팀팅파팎판팔팝패팩팬퍼퍽페펜펴편펼평폐포폭폰표푸푹풀품풍퓨프플픔피픽필핏핑하학한할함합항해핵핸햄햇행향허헌험헤헬혀현혈협형혜호혹혼홀홈홉홍화확환활황회획횟횡효후훈훌훔훨휘휴흉흐흑흔흘흙흡흥흩희흰히힘?!'''\n",
        "    self.font_dir = '/content/Font/'\n",
        "    self.font_list = os.listdir(self.font_dir)\n",
        "    try:\n",
        "      self.font_list.remove('.ipynb_checkpoints')\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  def ri(self, x, y):\n",
        "    return random.randint(x,y)\n",
        "  \n",
        "\n",
        "  def find_crop_size(self, img, color):\n",
        "    hor_set = set()\n",
        "    ver_set = set()\n",
        "    for f in range(img.shape[0]):\n",
        "      for s in range(img.shape[1]):\n",
        "        if img[f][s] != color:\n",
        "          hor_set.add(f)\n",
        "          ver_set.add(s)\n",
        "    if len(ver_set) == 0:\n",
        "      return 1\n",
        "    right, left, down, up = max(ver_set), min(ver_set), max(hor_set), min(hor_set)\n",
        "    margin = 5\n",
        "    crop_img = img[up-margin:down+margin, left-margin: right+margin].copy()\n",
        "    return crop_img\n",
        "\n",
        "\n",
        "  def generate_K_img(self, size=True, color=True, length = 1):\n",
        "    if size:\n",
        "      r_size = self.ri(10,40)\n",
        "    else:\n",
        "      r_size = 50\n",
        "\n",
        "    if color:\n",
        "      back_color = (self.ri(0,255))\n",
        "      text_color = (self.ri(0,255))\n",
        "    else:\n",
        "      back_color = (0,0,0)\n",
        "      text_color = (256,256,256)\n",
        "\n",
        "    text = random.choice(self.charecter)\n",
        "\n",
        "    r_font = self.font_dir + random.choice(self.font_list)\n",
        "    font = ImageFont.truetype(r_font, r_size)\n",
        "    img = np.full((r_size+50,length*r_size+50), back_color, dtype=np.uint8)\n",
        "    img = Image.fromarray(img)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw.text((15,15), text, font=font, fill=text_color)\n",
        "    img = np.array(img)\n",
        "    img=self.find_crop_size(img, back_color)\n",
        "\n",
        "    return img, text\n",
        "    \n",
        "K_img_gen = hangle_hanza()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hangul_utils in /usr/local/lib/python3.7/dist-packages (0.2)\n",
            "Archive:  /content/drive/MyDrive/KB_OCR/model2/Font2.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_9nnPwMrYS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430f1aea-feaa-4a75-d22d-b3ce1fa8842b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import datetime\n",
        "import itertools\n",
        " \n",
        "from tensorflow.keras import backend as K\n",
        " \n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import Input,GlobalMaxPooling2D,Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Reshape, LSTM, Lambda, add, concatenate\n",
        "from tensorflow.keras.models import Model, save_model, load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        " \n",
        "import numpy as np\n",
        "import random\n",
        "import multiprocessing\n",
        "from cv2 import resize\n",
        "from os import path, listdir\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "plt = matplotlib.pyplot\n",
        "\n",
        " \n",
        "!python --version\n",
        "print(\"tensorflow\",tf.__version__)\n",
        "print(\"numpy\",np.__version__)\n",
        "print(\"matplotlib\",matplotlib.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.11\n",
            "tensorflow 2.6.0\n",
            "numpy 1.19.5\n",
            "matplotlib 3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM9MUuSFuQKE",
        "outputId": "2b13eeed-2623-49c6-c631-ffe24991958b"
      },
      "source": [
        "characters = []\n",
        "characters += K_img_gen.charecter\n",
        "\n",
        "print(\"문자수\", len(characters))\n",
        "print(\"앞 20글자\", characters[0:20])\n",
        "print(\"뒤 20글자\", characters[-20:])\n",
        "\n",
        "model_path = '/content/drive/MyDrive/KB_OCR/model2/'\n",
        "img_length = 32\n",
        "num_classes = len(characters) + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자수 1010\n",
            "앞 20글자 ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
            "뒤 20글자 ['훌', '훔', '훨', '휘', '휴', '흉', '흐', '흑', '흔', '흘', '흙', '흡', '흥', '흩', '희', '흰', '히', '힘', '?', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtlZ6k5Du5K1",
        "outputId": "b2874ca4-f506-4c7e-d1a1-587aa8913e99"
      },
      "source": [
        "def labels_to_text(labels):     # index형 데이터 -> 글자 변환\n",
        "    return ''.join(list(map(lambda x: characters[int(x)], labels)))\n",
        " \n",
        "def text_to_labels(text):      # 글자 -> index형 데이터 변환\n",
        "    return list(map(lambda x: characters.index(x), text))\n",
        "\n",
        "class TextImageGenerator:\n",
        "    def __init__(self, K_img_gen, img_length=50, max_length=1):\n",
        "        self.cur_index = 0\n",
        "        self.batch_size = 1\n",
        "        self.img_length = img_length\n",
        "        self.K_img_gen = K_img_gen\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def next_batch(self): \n",
        "        while True:\n",
        "            X_data = np.ones([self.batch_size, self.img_length, self.img_length, 1])\n",
        "            Y_data = np.zeros([self.batch_size, self.max_length])   \n",
        "            input_length = np.ones((self.batch_size, 1)) * self.img_length\n",
        "            label_length = np.zeros((self.batch_size, 1))\n",
        "\n",
        "            \n",
        "            img, text = self.K_img_gen.generate_K_img(size=False)\n",
        "            img = cv2.resize(img, (self.img_length, self.img_length))\n",
        "            img = img.astype(np.float32)\n",
        "            img = (img / 255.0)\n",
        "            img = np.expand_dims(img, -1)\n",
        "\n",
        "            X_data[0] = img\n",
        "            letter = text_to_labels(text)\n",
        "            for point in range(len(letter)):\n",
        "                Y_data[0][point] = letter[point]\n",
        "            label_length[0] = len(text)\n",
        "\n",
        "            # dict 형태로 복사\n",
        "            inputs = {\n",
        "                'the_input': X_data,  # (bs, 128, 64, 1)\n",
        "                'the_labels': Y_data,  # (bs, 8)\n",
        "                'input_length': input_length,  # (bs, 1) -> 모든 원소 value = 30\n",
        "                'label_length': label_length  # (bs, 1) -> 모든 원소 value = 8\n",
        "            }\n",
        "            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1) -> 모든 원소 0\n",
        "            yield (inputs, outputs)\n",
        "\n",
        "img_gen = TextImageGenerator(hangle_hanza(), img_length=img_length)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/KB_OCR/model2/Font2.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPNrwbhPzAb-",
        "outputId": "85e50e67-fb41-4f4b-a82d-977c69d3a07c"
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    y_pred = y_pred[:,2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        " \n",
        "def get_Model(training=True):\n",
        "    inputs = Input(name='the_input', shape=(img_length, img_length, 1), dtype='float32')\n",
        " \n",
        "    # Convolution layer (VGG)\n",
        "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
        " \n",
        "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
        " \n",
        "    # CNN to RNN\n",
        "    inner = Reshape(target_shape=((64* 128)), name='reshape')(inner)\n",
        "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
        " \n",
        "    # RNN layer\n",
        "    lstm_1 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)\n",
        "    lstm_1b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
        "    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
        " \n",
        "    lstm1_merged = add([lstm_1, reversed_lstm_1b])\n",
        "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
        " \n",
        "\n",
        "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm1_merged)\n",
        "    y_pred = Activation('softmax', name='softmax')(inner)\n",
        " \n",
        "    labels = Input(name='the_labels', shape=[1], dtype='float32') \n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        " \n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        " \n",
        "    if training:\n",
        "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
        "    else:\n",
        "        return Model(inputs=[inputs], outputs=y_pred)\n",
        "\n",
        "model = get_Model()\n",
        "model.summary()\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 32, 32, 64)   640         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 16, 16, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 16, 16, 128)  73856       max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16, 16, 128)  512         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 8, 8, 128)    0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 8, 8, 256)    295168      max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 8, 8, 256)    1024        conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 256)    0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, 8, 8, 256)    590080      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 8, 8, 256)    1024        conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 256)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max3 (MaxPooling2D)             (None, 8, 4, 256)    0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 64, 128)      0           max3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 64, 64)       8256        reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm1_b (LSTM)                  (None, 64, 256)      328704      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm1 (LSTM)                    (None, 64, 256)      328704      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 64, 256)      0           lstm1_b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 64, 256)      0           lstm1[0][0]                      \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 256)      1024        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 64, 1011)     259827      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 64, 1011)     0           dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 input_length[0][0]               \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,889,075\n",
            "Trainable params: 1,887,155\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp-MW21lzhQz",
        "outputId": "135c1d69-cedd-40f9-c043-c4324a88744b"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath=model_path + '{epoch:02d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, mode='auto', save_best_only=True)\n",
        "\n",
        "log_dir = model_path + \"tensorbloard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "print(\"시작 시간:\", now)\n",
        "while True:\n",
        "  try:\n",
        "    history = model.fit(img_gen.next_batch(), steps_per_epoch=90\n",
        "                        ,validation_data=img_gen.next_batch(), validation_steps=10\n",
        "                        ,callbacks=[checkpoint, tensorboard_callback]\n",
        "                        ,epochs=500)\n",
        "  except:\n",
        "    pass\n",
        "now = datetime.datetime.now()\n",
        "print(\"종료 시간:\", now)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시작 시간: 2021-09-03 16:11:46.910415\n",
            "Epoch 1/500\n",
            "\r 1/90 [..............................] - ETA: 8s - loss: 8.3671"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 10s 107ms/step - loss: 7.3285 - val_loss: 62.2488\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 62.24885, saving model to /content/drive/MyDrive/KB_OCR/model2/01-62.2488.hdf5\n",
            "Epoch 2/500\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 7.2890 - val_loss: 47.9301\n",
            "\n",
            "Epoch 00002: val_loss improved from 62.24885 to 47.93015, saving model to /content/drive/MyDrive/KB_OCR/model2/02-47.9301.hdf5\n",
            "Epoch 3/500\n",
            "90/90 [==============================] - 10s 106ms/step - loss: 7.2893 - val_loss: 53.3546\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 47.93015\n",
            "Epoch 4/500\n",
            "66/90 [=====================>........] - ETA: 2s - loss: 7.3277Epoch 1/500\n",
            "90/90 [==============================] - 10s 106ms/step - loss: 7.3265 - val_loss: 30.1560\n",
            "\n",
            "Epoch 00001: val_loss improved from 47.93015 to 30.15596, saving model to /content/drive/MyDrive/KB_OCR/model2/01-30.1560.hdf5\n",
            "Epoch 2/500\n",
            "21/90 [======>.......................] - ETA: 6s - loss: 7.0129Epoch 1/500\n",
            " 3/90 [>.............................] - ETA: 18s - loss: 7.4615Epoch 1/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 7.2048 - val_loss: 18.3792\n",
            "\n",
            "Epoch 00001: val_loss improved from 30.15596 to 18.37917, saving model to /content/drive/MyDrive/KB_OCR/model2/01-18.3792.hdf5\n",
            "Epoch 2/500\n",
            "44/90 [=============>................] - ETA: 4s - loss: 7.2326Epoch 1/500\n",
            "18/90 [=====>........................] - ETA: 7s - loss: 7.4182Epoch 1/500\n",
            "23/90 [======>.......................] - ETA: 7s - loss: 7.2639Epoch 1/500\n",
            "42/90 [=============>................] - ETA: 5s - loss: 7.2410Epoch 1/500\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 7.0829 - val_loss: 27.8011\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 18.37917\n",
            "Epoch 2/500\n",
            "90/90 [==============================] - 9s 104ms/step - loss: 7.1979 - val_loss: 20.5269\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 18.37917\n",
            "Epoch 3/500\n",
            "77/90 [========================>.....] - ETA: 1s - loss: 7.1556Epoch 1/500\n",
            "12/90 [===>..........................] - ETA: 9s - loss: 7.3623Epoch 1/500\n",
            "22/90 [======>.......................] - ETA: 7s - loss: 6.8492Epoch 1/500\n",
            "36/90 [===========>..................] - ETA: 5s - loss: 7.0031Epoch 1/500\n",
            "34/90 [==========>...................] - ETA: 6s - loss: 7.2010Epoch 1/500\n",
            "17/90 [====>.........................] - ETA: 8s - loss: 7.0188Epoch 1/500\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 7.1497 - val_loss: 10.1059\n",
            "\n",
            "Epoch 00001: val_loss improved from 18.37917 to 10.10586, saving model to /content/drive/MyDrive/KB_OCR/model2/01-10.1059.hdf5\n",
            "Epoch 2/500\n",
            "70/90 [======================>.......] - ETA: 2s - loss: 7.1421Epoch 1/500\n",
            "18/90 [=====>........................] - ETA: 7s - loss: 7.1212Epoch 1/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 7.0074 - val_loss: 27.5797\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 10.10586\n",
            "Epoch 2/500\n",
            "26/90 [=======>......................] - ETA: 6s - loss: 7.1699Epoch 1/500\n",
            "42/90 [=============>................] - ETA: 5s - loss: 6.9934Epoch 1/500\n",
            "46/90 [==============>...............] - ETA: 4s - loss: 7.0619Epoch 1/500\n",
            "39/90 [============>.................] - ETA: 5s - loss: 7.2060Epoch 1/500\n",
            "21/90 [======>.......................] - ETA: 7s - loss: 7.0649Epoch 1/500\n",
            "25/90 [=======>......................] - ETA: 7s - loss: 7.0115Epoch 1/500\n",
            "13/90 [===>..........................] - ETA: 9s - loss: 6.8849Epoch 1/500\n",
            " 1/90 [..............................] - ETA: 8s - loss: 7.1205Epoch 1/500\n",
            "46/90 [==============>...............] - ETA: 4s - loss: 7.2877Epoch 1/500\n",
            " 3/90 [>.............................] - ETA: 20s - loss: 7.4626Epoch 1/500\n",
            " 1/90 [..............................] - ETA: 9s - loss: 7.6631Epoch 1/500\n",
            "17/90 [====>.........................] - ETA: 9s - loss: 7.1454Epoch 1/500\n",
            " 9/90 [==>...........................] - ETA: 10s - loss: 6.9739Epoch 1/500\n",
            " 1/90 [..............................] - ETA: 10s - loss: 7.0550Epoch 1/500\n",
            "17/90 [====>.........................] - ETA: 8s - loss: 7.1088Epoch 1/500\n",
            " 2/90 [..............................] - ETA: 23s - loss: 7.5989Epoch 1/500\n",
            " 1/90 [..............................] - ETA: 8s - loss: 6.3192"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "VTqyaHSZHXE4",
        "outputId": "5d6c7147-08b9-4f22-e49a-5dea3fadd6f0"
      },
      "source": [
        "predict_model = get_Model(training=False)\n",
        "try:\n",
        "    predict_model.load_weights(model_path + '01-10.1059.hdf5')\n",
        "    print(\"...Previous weight data...\")\n",
        "except:\n",
        "    raise Exception(\"No weight file!\")\n",
        " \n",
        "now = datetime.datetime.now()\n",
        "print(\"시작 시간:\", now)\n",
        "\n",
        "def decode_label(out):\n",
        "    z, x, y = out.shape\n",
        "    out = np.reshape(out,(int(x*y/num_classes),num_classes))\n",
        "    word = []\n",
        "    for letter in out:\n",
        "      word.append(letter.argmax())\n",
        "    out_best = [k for k, g in itertools.groupby(word)]\n",
        "    outstr = ''\n",
        "    for i in out_best:\n",
        "        if i < len(characters):\n",
        "            outstr += characters[i]\n",
        "    return outstr\n",
        "\n",
        "for _ in range(10):\n",
        "    img, text = K_img_gen.generate_K_img(size=False)\n",
        "    cv2_imshow(img)\n",
        " \n",
        "    img_pred = cv2.resize(img, (img_length, img_length))\n",
        "    img_pred = img_pred.astype(np.float32)\n",
        "    img_pred = (img_pred / 255.0)\n",
        "    img_pred = np.expand_dims(img_pred, axis=-1)\n",
        "    img_pred = np.expand_dims(img_pred, axis=0)\n",
        " \n",
        "    net_out_value = predict_model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    print('Predicted: %s ' % (pred_texts))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...Previous weight data...\n",
            "시작 시간: 2021-09-03 16:16:25.546585\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAArCAAAAAAbeFQDAAABSElEQVR4nM2VTXKDMAyFn2Rg0mmT+5+kB2va6VDgqQsDsWUDYRftbOnTv0E+cU70pP0rAs2RgX3hI5yM0J9KSRTTKQABaUYbNdA4DvouACC5ygFGkhMNAKahm7OqATaRZLR8JAMA2dUK2H25V1UVVb0zLEAtggGiIaguTSATVQXQq+X9mpaMNiJAXDOY9CNTbc1hXF3Yc4Al43oK4EnA7DGhetFORiQReoUIKK2UwB+6GQiSXM7gtQR+Eec7pCvaBoDjXJUDxBgA0DKgjWUpUBQtcRMMUhQn0bS8B4BwW1vjVql4DymG2sGl5P0B5mzUayuyP2m3tYWPwwi28aZLrZEc8eYd5AAB0Cz5Hgw+5whMfRAYjcD3rBAViDbNWAV+bFiLEhVV1f3BdUM0Ev+0S4nA5bJpsN/Wqkd15wMJt1pKe+KqesG/6D9hsG1rLqJeUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x43 at 0x7F7F564A8110>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 옛너렉z돗김쩐셈쩐슴노되훈싸훈대릿대애켓애 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAA3CAAAAABvbJbjAAABt0lEQVR4nM2Wy3KrMAxAj8ExBEiZ6ffc//8d2jS4PO27SCfY2E7pplNtAFlHkuWHEP/4mWQ/tP+LgIzoygsA0/vRCF9OlDoaoTeFBMiPRrC6mwHsUQCEBFiOA5UAluOArAB01FcMyFoAG51CrEqize6PpZ+OAFkrAZOBbBc9fgvkbQ7M17yRIF8CZA8UFwF83jBdVYkI4gOiKQH7MQLooSkIEA9QlwyYPsz901xVkwPyZbzGgLwugLUfOWWAmWHqqgqgkEsInGsBRn9CXQHQa7D9cDnhbqsNUIJVj3YbLTXA+lZU6DUCXIt1vr/ppSgB8TUwJqpkh8frNK01CUmc6TWufkRQpfDVGSBaX7f0G9DETqPYnWm1jI+URGj+PKX+fABZpg0YhqemrvzyVdmUMRN7c5faBcQ56lPULuCmlLgn/LS9lN5VUN2s2Ck8YJ4D72oP/G5Zz3m4QQKHDiCbhFOveI6HNXq9sztNTgTblRciq2H6BABDeYLhlggUpESiqz0DDkjYH055EMckAQPI18CH7bZC+SklCuveHz4wJAhnJfyUbKci28OuTnPcTzrSN335g39k/wGYQonFvRWZ3gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x55 at 0x7F7F561D8050>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 렉발현괴싸괴렉괴목다싸훈돗훈돗대켓대켓릿켓젓 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAAvCAAAAABvK30rAAABzElEQVR4nM2Wy5KbMBBFj8RDYGaMy57d/HQ+MZmqVFKpJHaMjXlJysLYRiB7ht1o16o+3NtS0yC+MHPJucAnJcKPJG3W+quZpaEIFvNcBWDnESF0swgxm4jA6KGgs9ar7dZDtLdopCHWwWaiET8iFoKTj2juEkuYmHqoEWbU5SyNXLCbAKG8T4icrvBJaHMLHeI5YGfHwMiUS+SYfxMAdZ9IEnZmnD/RGN55jt3dojS3v2xPRKsgCMPm54iQTxz69pGLRRbCaQ8EElZne39al3iW7AGxSFMlgL5h42tC0440VrSlyJ6yc2m6OFUdnDu31sbo/m5vRBZTbPIAgLKorsVGUP7wVr6BNWDLUFHunYxBVw0IpQDavwfzosan6Se0FdTbvkdqN6PxEt03Vbe9cd0NMqJ7GrSX/dg1JbDDB3gmg4wdU6Me8RHKLWNsykMkE8LVmE5qg2kAgkiaavySe4kiqlSi4lgCzZt9jxAqSeKVuFqS5pErkaZpckm2bddiDlo5E/RGyCyIkr7Fbd3UTXO5gslR9cRrco7quqoaZzbEYHxECJhjeXT1AQxoH/F9qavpvAUoluroI5rf3nRAv6na3Xn/izMCPuk/w3/RfKaOVoGn/AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=49x47 at 0x7F7F5625E5D0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 히헬둠촌둠싸렉돗김돗김돗아노되훈대릿애릿켓애켓애 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAvCAAAAACA6RYVAAACuElEQVR4nM2W30tTcRTAP3d3tuacpmYyf2sarCRHPY3QVPJHURTYW70U+RThY9D/EAQ9BD0JFfQQSQb1EtJMRQwkCxlOQZyk4GyO2fRqbuvhu7v7Va9T3zwv59xzzmffc+79nsOUKQ4nlkPmH3lg4cv0voDVMAeGV6C6sy4zoBiv9elvYF9EKqleqNkXz5cOBnS0pIzZwMEAbjSljOgBAW55AXBmasK67el2fAw8XQ6zzIT4bWX75UuG/1Jpkjw3NRV+YpNOiM9rmqZtWpzF5SqwEs0plIFXE4Cv3QAivUE9Zq8/vhyMYXkkHZScBvh6yYHe9Ew6n/Xv3/wxSPQlDWB+DUAbIg3Ed5cdXDXsOaEiBrCVjmXnpQw12wC2JGU1TiisyrUWeYY/iKjXSiKYdDiylTQXN4AyV2lVtQvA1y+CLW0/Jv1rgJJ9vkkGtn+HxLtRAOydjeOvDbdT9OPuZseXXu8VA3S1VaXUcKv21Z0lpfKfhQDwtAFFWf8A1Lz8wtbJj+bAmMhXvQCWWj9KQ8cpBQjseksAJEeEvisu64OJn80VwlNtDgyJAy42iEfF49EjuUrSpKTwJ6HbkCWRVJl8nzTpIfBmI9XJNWOoYqND0Tz7IiYl+fr1yzbwy11TZyfWF41GNSAS0XFFAtY+i/wzLh+h0KC1/UponJ3SDOmZHtkE4EL3zTqArQEiRqJ+m/IloM4BcPmOipg0baXmtH5vKx6XCCNHKqmy5+Wycr0FOCYci2cf8nYMW0F+VaulZAEAp9z0yZ7lwhwAmw6At7HADsAJ4XPIAI7UbtEBMNaHALJsUg+GSEBa/mCk7gUsyWPuB2AjlgmIhyRfuVBhU8BdJrS8kGsyAdZ7DgBF3q8uIN973w27ditAdHBEK+6qlTzxmdXy4pRtAoAWOKeauPcGMskR/CfwHzrzylDUiN9mAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x47 at 0x7F7F5618F650>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: zzzz겪z핏겪z겪숟겪숟겪솜유렬릿켓릿켓릿켓꼼 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACwAAAA1CAAAAAAfNlaOAAAAwklEQVR4nGMMYCAeMJGgdrAoZiFCja4OA8POd3RwhpA7FqmtnygymczQuHKZuiaPKqaPYkQM6uigypy+MyDOGE1IA1R8MfKLiIpw7HlPSDEbvwC/gAArAwMDgwRWxfzMzGysbGxc3Fzc3Oxw0T8vMZzxjYGBQVYW3fyv79++efsXQ/GP55LIqv5/+/zp08cPv9B1Q51xzFCG+fevX79//fj27du37/+x+gSm+NfJk9jlUcAgicFRxWQrZgwYFM4gSTEAIAEv3bhoiUwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=44x53 at 0x7F7F56460110>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 히너벼싸괴목괴목덕노싸훈싸훈끌훈슷릿슷릎켓럿켓젓 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAA1CAAAAADNZlzWAAABRElEQVR4nM1WS3aDMAwcA8VJ2vvfrdegKUnxr4tAnixLYJIsopUxGmmkkQ3mGzut2Qt4U0RH1sde9kmjVxDWKGEtRVBWk0Yki0QR4znJiCwUZQXnegDTyAB5nE54p2QSWNXZc3osW59sw+mVz2m5kL2Pe1k16oNiMWyw8le+kbVbQES3mvElemgTPJukh+VjkmglwlyZUxHEnTVWEbK1ZJ0jJgVCBWGshl5qXqKDxSpPfwovjVWNPXw+Th8VvnEMd0Rjq/jY8c5qYzByHAAg+A03AEuT5zp+TEWam7yLHmn9kipY7TGieXcwABCvQXPmiOO8bodaVku/WtFRynFx/U1Is9oFOrveh/L4rbFCfnLqEDWivORrgK6YMppb+qp9FTECkYjdPkrpLQnM6rjICGqsDjccOmHuHamMVx5+t3K85//VP689VNC1P8hgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=49x53 at 0x7F7F5663C3D0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: zzz핏셈핏셈핏렉덕끼숟솜숟솜숟솜유대릿대릿켓꼼 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB8AAAAiCAAAAACCIV2WAAABSElEQVR4nLXTz0sCQRTA8e+2ruWCK4JgP7ZNMMKkLtEtAhGik2D9oxHRLQoKOgRGEQmWSeYiIVESotKodXDTWbO9+U6z7zM785g3o2TxjClvnrj75A9r3VQBus/5yl/XUzHqlZY+G1Hj8eKZGPFQxhDnBQBzJ8Cy//jbtb++Z3QOCwDYR4CVcNeX1jmtOeO3MrDg8lULuzjY6wloy65swNWw1IcaIi/XFwvx8Tr03kG03pR9CV7kk+hWnYGzvgk1xkXfVQMaHh4Y1Dvep/mvU/1sB/B7eAswPPyrBVEPpwqWl5fBcE/QLNkfm7Clyv/tpnySd3MQ3pY4vXjSkZy7CiRTvysE91eu+x1Qsk4qkIlAPVcSEF5LaDeXuB0tHQd6TRH00bu4Z9TB3JxTAET+dtAs+f7b9sy8rjU+38Uw53oftEuMxKTf5w/Xf1bpmrCIZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=31x34 at 0x7F7F5663C890>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 온발너렉돗괴솜땜목덕노싸훈싸훈돗훈끌훈대릿켓럿젓 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACkAAAAvCAAAAABbUrw3AAACA0lEQVR4nMWUW2/TQBCFz+yuL4mbhsRNicJF9ALil/OPEBISIqWUi0JD09zW9l54aO3sxhbxC2JedjX69pyZ2bXpHVoGawv+Z1Lstj9mYpTSPmA/aAyf+ZoE9f3j/T4pNXC/536aEvKrL6ZuGu6502S8+L1eZBde7QEzSPc0ATY4fxPLmS8aIuzXSADRKzb3MwZ9aiIRjK31EhpRVbAf6dCblC3Jhsn7I1WPrR++Iw0SdXercmMs54zzSkEhgEMW1zlnRinnlBBBMqqTyzUKACDBiACYDEpJORA1sisUgribdErT/Nc2PD4mALos8GGJ32rutRxOdnWGLln21xDK19zlZc6OBAA9y0Un4pw3k/JaAuAvj4D57p0wbwEAFJ8lBIO+2gL9qErzuuaNCp8n5u5WTi+D8PVWc8YZe29ZjdwsxXkANhx8vZteEnUBANqWmo77AsMAAOiFkNXnpEFU05ToPu4CRbArZYw1eSnpkrpMKhn0sk/ab90l+cPdA9/siGYaAHUSPW8gk9VPljAUN8twiBOmw07Ccdvkni43U4psBowJ8aQsqdR0eudnT5mVGfCkv0uq6mNxJ89O000G6nThkg3uAHivBz+KJvemsBnK/9QBcq2RtSOXgGxHrgBTtCIZANWK7AMUtSLTGCf1l9wUdJHHTiF/CxZXuwOkc+YfkH8AXwikYde67MwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=41x47 at 0x7F7F566F23D0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 헬촌둠쩐렉돗김돗김돗덕노되훈대릿대애켓애 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACkAAAAiCAAAAADnzK/pAAABeElEQVR4nMXUOVPCQBiA4XdzcAU5ctlIZWWhhRb+Sn+TraW9pTM6A0kAQSBCiMUuuQgzdKRI5ss++x2ZJOKFMw/tXHhhaQCwf1sCdyN5L3lPaTwokL7ujMdBJoWeAKGS0zFwa8lgHpP8DrLq4vkeiFSaAGCighCwi33edCBe1cgI2u3SRF6W9G8BECWyzSm45dndTAZySHmZJeCUpS0KUs/KhxxJow/rtVocmQV51ShLHFV+uQHfh80C2M8OKWtkCPrQB8bAdF8jh5qUAdiaK2T5EIRdldoQVjFpBC6GDbMtRNA3qlKVn+3AAx/SgCRvsyjlEw2gbYFsNEoPz70ke6aSLtDpwiSNQB8cS2HDcjVXWXzYzkM5aFXiAB8pwlGSr5+8zSP5DQMT5PkzPSG7TchGEB7swezVSbVfDesD8sWpkS6A2ZeBJ/LN9TldlcWwCwWqsmUV13ygadVLnKrMU6qvOFuc02odgo4fc31Kel4xeiqtXfYP9g+qW2wvffuY2QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=41x34 at 0x7F7F562142D0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 히튼z튼쩐벼돗신목돗목덕노돗훈싸훈슷릿켓릎켓릎켓애 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADUAAAA4CAAAAAB4E+9yAAABuElEQVR4nNWVXZLsIAiFzwH77mb2v7eOwn0wfyqJma6pmhoeUonhEz0C8gsfmHwC/U1K0nSqNA65KswcrF/2kFoS5Qj39kcU7K26BgIsgEIKKIWIvO8ptIyw29+ZEnjjTAAEKQSAXC4o3YNwjH4eOlPZ0/HTu2XaKVS7r2IqhJndStFT8AxOgIDaVyUiBOBuz89L0ro7Uhrt7ih5AV7MQYoiyfKE4guwBesCXxAdogVFoQDy9mGlDkwp4pwjBnA48x+rZW9mF2A884AqOIkkWgdai2o5J8i/4g5QBbD8hELxRO4/ygjFuWFvUX47owCLOtOUCowCwmsjqFRf+433uQ0Ai+1Uqps4/LqXk8lBvZP2ieMIes/WCNZ95aIKAG7u8FkD2NXwnEVm0g0U7tQeekmnPNkvjyoEvDTJ2FKpbs7dUSXnKgL1hiouEonZ32JdPywFSQHPu39oY0aZTtPwogPMDmCevUrCva3nC4rbU7asvdFws9fxWpPxVsPNluoar+OSuq62aqOGH91fkbGfa6QcgJbdi1QBtlvmOlZRaHCNyEnGgMouQ8PwNsnC3hvcqV3gmcOvU/8Bxq2zsOjDLkEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=53x56 at 0x7F7F5664D910>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 괴z괴z괴z다싸대켓럿켓젓 \n"
          ]
        }
      ]
    }
  ]
}