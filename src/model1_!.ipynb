{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aloml2543/KB_OCR/blob/main/src/model1_!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TJwvNBmi3XmH",
        "outputId": "0d812814-98f5-454d-e3e5-7b1bd957a75c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhttps://github.com/qjadud1994/CRNN-Keras\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "https://github.com/qjadud1994/CRNN-Keras\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dz19YYgGggm",
        "outputId": "9fcda48c-76d5-495b-dc31-bbd236688c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.7.11\n",
            "tensorflow 2.6.0\n",
            "numpy 1.19.5\n",
            "matplotlib 3.2.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import os, random\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import datetime\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import Input,GlobalMaxPooling2D,Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Reshape, LSTM, Lambda, add, concatenate\n",
        "from tensorflow.keras.models import Model, save_model, load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from cv2 import resize\n",
        "from os import path, listdir\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import glob\n",
        "plt = matplotlib.pyplot\n",
        "img = matplotlib.image\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (25,1)\n",
        "\n",
        "!python --version\n",
        "print(\"tensorflow\",tf.__version__)\n",
        "print(\"numpy\",np.__version__)\n",
        "print(\"matplotlib\",matplotlib.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5j8Netvbcfs",
        "outputId": "8d213ec7-b095-4bba-e062-97dd3c61b98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/KB_OCR/DATA/snukb_dataset.zip\n",
            "replace /content/test/images/30060.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#데이터셋 가져오기\n",
        "!unzip \"/content/drive/MyDrive/KB_OCR/DATA/snukb_dataset.zip\" -d -n \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAYpfm3YGj0z"
      },
      "outputs": [],
      "source": [
        "# Path to the data directory\n",
        "data_dir = Path(\"/content/train/images/\")\n",
        " \n",
        "# Get list of all the images\n",
        "train_label = pd.read_csv('/content/train/train.csv')\n",
        "train_label.sort_values(by=['index'], axis=0, inplace=True, ascending=True)\n",
        "image_dir = [str(index) + '.jpg' for index in list(train_label.index.to_numpy())]\n",
        "labels = train_label.label.to_numpy()\n",
        "characters = list(set(char for label in labels for char in label))\n",
        "\n",
        "\n",
        " \n",
        "# Batch size for training and validation\n",
        "batch_size = 1\n",
        " \n",
        "# Desired image dimensions\n",
        "img_width = 128\n",
        "img_height = 64\n",
        " \n",
        "max_length = max([len(label) for label in labels])\n",
        "num_classes = len(characters) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiDW-EQiztw1"
      },
      "outputs": [],
      "source": [
        "# # Input data generator\n",
        "def labels_to_text(labels):     # letters의 index -> text (string)\n",
        "    return ''.join(list(map(lambda x: characters[int(x)], labels)))\n",
        "\n",
        "def text_to_labels(text):\n",
        "    output = list(map(lambda x: characters.index(x), text))\n",
        "    while(len(output) != 38):\n",
        "      output.append(1)    # text를 letters 배열에서의 인덱스 값으로 변환\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0pcPkP3V0o",
        "outputId": "7af6546a-845b-4945-8b26-028a982d1247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          [(None, 128, 64, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 64, 64)  256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 128, 64, 64)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 32, 128)  512         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 32, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 16, 256)  1024        conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 16, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 16, 256)  1024        conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 16, 256)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 8, 512)   2048        conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 8, 512)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 8, 512)   2048        conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 8, 512)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "con7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 4, 512)   2048        con7[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 4, 512)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 2048)     0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm1_b (LSTM)                  (None, 32, 256)      328704      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm1 (LSTM)                    (None, 32, 256)      328704      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 32, 256)      0           lstm1_b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 256)      0           lstm1[0][0]                      \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 256)      1024        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "lstm2_b (LSTM)                  (None, 32, 256)      525312      batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lstm2 (LSTM)                    (None, 32, 256)      525312      batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 32, 256)      0           lstm2_b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 512)      0           lstm2[0][0]                      \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 512)      2048        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 32, 1212)     621756      batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 32, 1212)     0           dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, 38)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 input_length[0][0]               \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 8,021,756\n",
            "Trainable params: 8,015,740\n",
            "Non-trainable params: 6,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN\n",
        "    # tend to be garbage:\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "def get_Model(training=True):\n",
        "    input_shape = (img_width, img_height, 1)     # (128, 64, 1)\n",
        "\n",
        "    # Make Networkw\n",
        "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 128, 64, 1)\n",
        "\n",
        "    # Convolution layer (VGG)\n",
        "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 128, 64, 64)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)\n",
        "\n",
        "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 32, 128)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)\n",
        "\n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  # (None, 32, 8, 256)\n",
        "\n",
        "    inner = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 512)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = Conv2D(512, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)\n",
        "\n",
        "    inner = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 512)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "\n",
        "    # CNN to RNN\n",
        "    inner = Reshape(target_shape=((32, 2048)), name='reshape')(inner)  # (None, 32, 2048)\n",
        "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
        "\n",
        "    # RNN layer\n",
        "    lstm_1 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)\n",
        "    lstm_1b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
        "    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
        "\n",
        "    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
        "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
        "    \n",
        "    lstm_2 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
        "    lstm_2b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
        "    reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
        "\n",
        "    lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
        "    lstm2_merged = BatchNormalization()(lstm2_merged)\n",
        "\n",
        "    # transforms RNN output to character activations:\n",
        "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
        "    y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "    labels = Input(name='the_labels', shape=[max_length], dtype='float32') # (None ,8)\n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
        "\n",
        "    # Keras doesn't currently support loss funcs with extra parameters\n",
        "    # so CTC loss is implemented in a lambda layer\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
        "\n",
        "    if training:\n",
        "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = get_Model()\n",
        "model.summary()\n",
        "ada = Adam()\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIM5F_l33czF",
        "outputId": "9dac5a0e-4928-4125-af8b-bb4c62852852"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 64/30060 [00:01<05:56, 84.08it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30060  Image Loading start...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30060/30060 [00:41<00:00, 728.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "30060  Image Loading finish...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "class TextImageGenerator:\n",
        "    def __init__(self, img_dirpath,img_dir,label_df, img_w, img_h,\n",
        "                 batch_size, downsample_factor, max_text_len=9):\n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "        self.label_df = label_df\n",
        "        self.batch_size = batch_size\n",
        "        self.max_text_len = max_text_len\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.img_dirpath = img_dirpath                  # image dir path\n",
        "        self.img_dir = img_dir     # images list\n",
        "        self.n = len(self.img_dir)                      # number of images\n",
        "        self.indexes = list(range(self.n))\n",
        "        self.cur_index = 0\n",
        "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
        "        self.texts = []\n",
        "\n",
        "    ## samples의 이미지 목록들을 opencv로 읽어 저장하기, texts에는 label 저장\n",
        "    def build_data(self):\n",
        "        print(self.n, \" Image Loading start...\")\n",
        "        for i, img_file in enumerate(self.img_dir):\n",
        "            img = cv2.imread(self.img_dirpath + img_file, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
        "            img = img.astype(np.float32)\n",
        "            img = (img / 255.0) * 2.0 - 1.0\n",
        "            label_df = self.label_df[self.label_df['index'] ==int(img_file[:-4])]\n",
        "\n",
        "            self.imgs[i, :, :] = img\n",
        "            self.texts.append(self.label_df.label.to_list()[0])\n",
        "        print(len(self.texts) == self.n)\n",
        "        print(self.n, \" Image Loading finish...\")\n",
        "\n",
        "    def next_sample(self):      ## index max -> 0 으로 만들기\n",
        "        self.cur_index += 1\n",
        "        if self.cur_index >= self.n:\n",
        "            self.cur_index = 0\n",
        "            random.shuffle(self.indexes)\n",
        "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
        "\n",
        "    def next_batch(self):       ## batch size만큼 가져오기\n",
        "        while True:\n",
        "            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])     # (bs, 128, 64, 1)\n",
        "            Y_data = np.ones([self.batch_size, self.max_text_len])             # (bs, 9)\n",
        "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)  # (bs, 1)\n",
        "            label_length = np.zeros((self.batch_size, 1))           # (bs, 1)\n",
        "\n",
        "            for i in range(self.batch_size):\n",
        "                img, text = self.next_sample()\n",
        "                img = img.T\n",
        "                img = np.expand_dims(img, -1)\n",
        "                X_data[i] = img\n",
        "                Y_data[i] = text_to_labels(text)\n",
        "                label_length[i] = len(text)\n",
        "\n",
        "            # dict 형태로 복사\n",
        "            inputs = {\n",
        "                'the_input': X_data,  # (bs, 128, 64, 1)\n",
        "                'the_labels': Y_data,  # (bs, 8)\n",
        "                'input_length': input_length,  # (bs, 1) -> 모든 원소 value = 30\n",
        "                'label_length': label_length  # (bs, 1) -> 모든 원소 value = 8\n",
        "            }\n",
        "            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1) -> 모든 원소 0\n",
        "            yield (inputs, outputs)\n",
        "num_cores = multiprocessing.cpu_count() # cpu core 개수\n",
        "\n",
        "train_file_path = '/content/train/images/'\n",
        "tiger_train = TextImageGenerator(train_file_path,tqdm(image_dir),train_label, 128, 64, batch_size, 4, max_text_len=max_length)\n",
        "tiger_train.build_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tgbtwkSq7sm4",
        "outputId": "8f930faa-798d-4b08-a8f8-08e0fce0da1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22884/30060 [=====================>........] - ETA: 28:11 - loss: 0.2071"
          ]
        }
      ],
      "source": [
        "early_stopping_patience = 10\n",
        "\n",
        "# Add early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"loss\", patience=early_stopping_patience, restore_best_weights=True\n",
        ")\n",
        "now = datetime.datetime.now()\n",
        "print(\"시작 시간:\", now)\n",
        "model.fit(tiger_train.next_batch(),\n",
        "                    steps_per_epoch=int(tiger_train.n / batch_size),\n",
        "                    callbacks=[early_stopping],\n",
        "                    epochs=500)\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "print(\"종료 시간:\", now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dyLkXXfbnOr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "model1_!.ipynb",
      "provenance": [],
      "mount_file_id": "1obAaA97D6h2yKXIMjWy7tALEtzIc2WuM",
      "authorship_tag": "ABX9TyP2drsUT8uqr0H2iVvnLhVI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}